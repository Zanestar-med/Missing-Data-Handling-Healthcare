{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RspRs_rR0nza"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "sklearn.set_config(transform_output='pandas')\n",
    "\n",
    "FILE_PATH = \"NHANES_hypertension.pkl\"\n",
    "IT_IMP_SUBSET = 2000\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7PKqMQO0Qyl"
   },
   "source": [
    "# Assignment 3: Handling missing data\n",
    "\n",
    "In this assignment, you will explore different methods for handling missing values in the development of prediction models. You will use a data set based on the National Health and Nutrition Examination Survey (NHANES) run by the Centers for Disease Control and Prevention (CDC) in the USA: https://www.cdc.gov/nchs/nhanes/index.htm.\n",
    "\n",
    "\n",
    "## Goal\n",
    "\n",
    "* Your goal is to predict hypertension (high blood pressure) from a number of subject covariates. \n",
    "* You will compare impute-then-regress classifiers to methods that handle missing values natively.\n",
    "\n",
    "## Data\n",
    "\n",
    "The NHANES survey is possible to download from the CDC but is spread over 100s of CSV files. For your convenience, we have compiled a .pkl file with a dataframe for this assignment. We cannot share it publicly on the web so instead...\n",
    "\n",
    "* For this assignment, you will need to download a .pkl data file from Canvas \n",
    "* Place the file with the name ```NHANES_hypertension.pkl``` in the same directory as this notebook\n",
    "* The covariates are described in the file ```NHANES_hypertension.codes.txt```, also available on Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_kBFRdh0Oe8"
   },
   "outputs": [],
   "source": [
    "D_full = pd.read_pickle(FILE_PATH)\n",
    "D_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 — Exploration & imputation\n",
    "\n",
    "### Data exploration & setup\n",
    "\n",
    "* The columns 'SEQN' and 'YEAR' represent the subject ID and year of survey, respectively. These should *not* be used as input for prediction.\n",
    "* The outcome column $Y$ is called 'HYPERT'\n",
    "* The columns 'BPXSY1', 'BPXDI1', 'BPXOSY1', 'BPXODI1' all measure the blood pressure and are used to compute the outcome. These should *not* be used as input for prediction. \n",
    "\n",
    "\n",
    "1. Report the frequency of missing values in each input column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Remove columns with more than 50% missingness and report which columns you removed and which remain\n",
    "* Variable types can be found in the property ```dtypes``` of the dataframe. Categorical variables have the type 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Perform one-hot encoding of categorical variables such that missing values are encoded as a separate category. For example, if a binary variable ```Test``` has values 0, 1 and missing values NaN, the categories should be ```Test_0```, ```Test_1``` and ```Test_NaN``` (although, the names are up to you)\n",
    "4. Split your data into a training portion (80%) and a test portion (20%) with random_state=0\n",
    "5. Fit a standard scaler to the numeric features in the training portion and apply that to both training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Fit a constant imputer for numeric (non-categorical) input variables on the training set using the variable *median* as constant. Categorical variables should not be imputed since they are handled by the one-hot encoding. Impute missing values both in the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jj7g4NwH1c0b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Fit an IterativeImputer (akin to MICE) using scikit-learn for numeric (non-category) variables. Impute missing values both in the training and test sets. (Don't use posterior sampling here. We do single, not multiple imputation in this assignment.)\n",
    "* Since IterativeImputer is quite slow for large samples, fit the imputer to a subset of the training set of size ```IT_IMP_SUBSET```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Evaluate both imputation strategies. \n",
    "* Since the value of missing variables is unknown, do this by: \n",
    "* Copying the test set into a new data frame\n",
    "* Adding missing values to 5% to the *observed values* of data frame selected uniformly at random (make them NaN). \n",
    "* Report the MSE on the modified subset of values, compared to the original observations, where each error is normalized by the standard deviation of the corresponding column in the training set.\n",
    "* Are the results expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "er4l_NwY0-O9"
   },
   "source": [
    "## Problem 2 — Predict hypertension\n",
    "\n",
    "In this problem, you will use the imputed data sets for predicting hypertension with column name ```HYPERT``` using the other variables as input (excluding columns removed previously). You will compare classifiers fit to the imputed data sets, and classifiers that handle missing values natively. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit LogisticRegression (LR) models to the two training data sets imputed with the constant and iterative imputer, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fit an [HistGradientBoostingClassifier](https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html) (HGBC) to the *unimputed* data set with missing values. The HGBC handles missing values natively by learning default rules which are used when a missing value is encountered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Report the training and test set AUROC for all models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Is imputation better than native handling of missing values in this case? Can you tell from the results you already have? If not, perform an experiment to gather more evidence. Describe this experiment, run it, and give your conclusions below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 — Complete-case analysis\n",
    "\n",
    "In this problem, you will compare classifiers fit only to complete cases to methods aimed at overcoming missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit complete-case classifiers (LR and HGBC) by dropping all rows with missing values in your selected input columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compare your classifiers fit to the full data sets (imputed and with missing values) to the complete-case classifiers on the test set, restricted to complete cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What can you say about the performance of your complete-case models on the full population? Would the results from the complete-case subset transfer (for example, if the missing values in the full population were observed)? \n",
    "\n",
    "4. Under what conditions do results from complete-case analysis generally transfer to a population with missingness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Investigate how the complete cases differ from the overall population. Can you see substantial differences in distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
